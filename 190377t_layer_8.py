# -*- coding: utf-8 -*-
"""190377T_Layer_8.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fOmKxnco_cmhLHhH5et9XOefJlzyHmIg
"""

import pandas as pd

labels = ['label_1', 'label_2', 'label_3', 'label_4']
features = [f'feature_{i}' for i in range (1,769)]

"""Reading Datasets"""

train_df = pd.read_csv('./8/train.csv')
test_df = pd.read_csv('./8/test.csv')
valid_df = pd.read_csv('./8/valid.csv')

"""Data Preprocessing -
Remove NaN values,
Data Scaling
"""

from sklearn.preprocessing import RobustScaler

id = ['ID']

x_train = {}
y_train = {}

x_valid = {}
y_valid = {}

x_test = {}

for label in labels:
  tr_df = train_df[train_df['label_2'].notna()] if label == 'label_2' else train_df
  vl_df = valid_df[valid_df['label_2'].notna()] if label == 'label_2' else valid_df
  tst_df = test_df.drop('ID', axis=1)

  scaler = RobustScaler()
  x_train[label] = pd.DataFrame(scaler.fit_transform(tr_df.drop(labels, axis = 1)), columns = features)
  y_train[label] = tr_df[label]

  x_valid[label] = pd.DataFrame(scaler.transform(vl_df.drop(labels, axis = 1)), columns = features)
  y_valid[label] = vl_df[label]

  x_test[label] = pd.DataFrame(scaler.transform(tst_df), columns = features)

"""Feature Engineering - Applying PCA"""

from sklearn.decomposition import PCA

x_train_pca = {}
y_train_pca = y_train

x_valid_pca = {}
y_valid_pca = y_valid

x_test_pca = {}

for label in labels:
  if (label == 'label_2'):
    pca = PCA(n_components= 0.99, svd_solver='full')
  else:
    pca = PCA(n_components= 0.99, svd_solver='full')
  pca.fit(x_train[label])
  x_train_trf = pd.DataFrame(pca.transform(x_train[label]))
  x_valid_trf = pd.DataFrame(pca.transform(x_valid[label]))
  x_test_trf = pd.DataFrame(pca.transform(x_test[label]))
  x_train_pca[label] = x_train_trf
  x_valid_pca[label] = x_valid_trf
  x_test_pca[label] = x_test_trf
  print(label)
  print(x_train_trf.shape)
  print(x_valid_trf.shape)
  print(x_test_trf.shape)
  print('...............................................................')

"""Label 1 - Hyper Parameter Tuning and Cross Validation"""

from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score
import numpy as np

param_dist = {
    'C': np.logspace(-2, 2, 5),
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': np.logspace(-4, 0, 5)
}


svm = SVC()

random_search = RandomizedSearchCV(
    estimator=svm, param_distributions=param_dist, scoring='accuracy', cv=5, verbose=1, n_jobs=-1, n_iter=6, random_state=42
)


random_search.fit(x_train_pca[labels[0]], y_train_pca[labels[0]])

best_params = random_search.best_params_
best_model = random_search.best_estimator_

print(best_params)
print(best_model)

y_pred_hype_1 = best_model.predict(x_valid_pca[labels[0]])
label_1_hype = best_model.predict(x_test_pca[labels[0]])
accuracy = accuracy_score(y_valid_pca[labels[0]], y_pred_hype_1)
print(f'Accuracy on test data: {accuracy}')

"""Label 1 - Best Model"""

from sklearn import svm
from sklearn import metrics

clf = svm.SVC(C=63.0957344480193, gamma=0.015848931924611134, kernel='poly')
clf.fit(x_train_pca[labels[0]], y_train_pca[labels[0]])
y_pred_label_1_99 = clf.predict(x_valid_pca[labels[0]])
label_1_99 = clf.predict(x_test_pca[labels[0]])
print(labels[0], metrics.accuracy_score(y_valid_pca[labels[0]], y_pred_label_1_99)) #0.952

"""Label 2 - Hyper Parameter Tuning and Cross Validation"""

from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score
import numpy as np

param_dist = {
    'C': np.logspace(-2, 2, 5),
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': np.logspace(-4, 0, 5)
}


svm = SVC()

random_search = RandomizedSearchCV(
    estimator=svm, param_distributions=param_dist, scoring='accuracy', cv=5, verbose=1, n_jobs=-1, n_iter=2, random_state=42
)


random_search.fit(x_train_pca[labels[1]], y_train_pca[labels[1]])

best_params = random_search.best_params_
best_model = random_search.best_estimator_

print(best_params)
print(best_model)

y_pred_hype_2 = best_model.predict(x_valid_pca[labels[1]])
label_2_hype = best_model.predict(x_test_pca[labels[1]])
accuracy = accuracy_score(y_valid_pca[labels[1]], y_pred_hype_2)
print(f'Accuracy on test data: {accuracy}')

"""Label 2 - Best Model"""

from sklearn import svm
from sklearn import metrics

clf = svm.SVC(C=63.0957344480193, gamma=0.015848931924611134, kernel='poly')
clf.fit(x_train_pca[labels[1]], y_train_pca[labels[1]])
y_pred_label_2_99 = clf.predict(x_valid_pca[labels[1]])
label_2_99 = clf.predict(x_test_pca[labels[1]])
print(labels[1], metrics.accuracy_score(y_valid_pca[labels[1]], y_pred_label_2_99))  #0.9334239130434783

"""Label 3 - Hyper Parameter Tuning and Cross Validation"""

from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score
import numpy as np

param_dist = {
    'C': np.logspace(-2, 2, 5),
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': np.logspace(-4, 0, 5)
}


svm = SVC()

random_search = RandomizedSearchCV(
    estimator=svm, param_distributions=param_dist, scoring='accuracy', cv=5, verbose=1, n_jobs=-1, n_iter=6, random_state=42
)


random_search.fit(x_train_pca[labels[2]], y_train_pca[labels[2]])

best_params = random_search.best_params_
best_model = random_search.best_estimator_

print(best_params)
print(best_model)

y_pred_hype_3 = best_model.predict(x_valid_pca[labels[2]])
label_3_hype = best_model.predict(x_test_pca[labels[2]])
accuracy = accuracy_score(y_valid_pca[labels[2]], y_pred_hype_3)
print(f'Accuracy on test data: {accuracy}')

"""Label 3 - Best Model"""

from sklearn import svm
from sklearn import metrics

clf = svm.SVC(kernel= 'rbf')
clf.fit(x_train_pca[labels[2]], y_train_pca[labels[2]])
y_pred_label_3_99 = clf.predict(x_valid_pca[labels[2]])
label_3_99 = clf.predict(x_test_pca[labels[2]])
print(labels[2], metrics.accuracy_score(y_valid_pca[labels[2]], y_pred_label_3_99)) #0.9986666666666667

"""Label 4 - Hyper Parameter Tuning and Cross Validation"""

from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
from sklearn.metrics import accuracy_score
import numpy as np


param_dist = {
    'C': np.logspace(-2, 2, 5),
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': np.logspace(-4, 0, 5)
}


svm = SVC()

random_search = RandomizedSearchCV(
    estimator=svm, param_distributions=param_dist, scoring='accuracy', cv=5, verbose=1, n_jobs=-1, n_iter=6, random_state=42
)


random_search.fit(x_train_pca[labels[3]], y_train_pca[labels[3]])

best_params = random_search.best_params_
best_model = random_search.best_estimator_

print(best_params)
print(best_model)

y_pred_hype_4 = best_model.predict(x_valid_pca[labels[3]])
label_4_hype = best_model.predict(x_test_pca[labels[3]])
accuracy = accuracy_score(y_valid_pca[labels[3]], y_pred_hype_4)
print(f'Accuracy on test data: {accuracy}')

"""Label 4 - Best Model"""

from sklearn import svm
from sklearn import metrics

clf = svm.SVC(C=63.0957344480193, gamma=0.015848931924611134, kernel='poly')
clf.fit(x_train_pca[labels[3]], y_train_pca[labels[3]])
y_pred_label_4_99 = clf.predict(x_valid_pca[labels[3]])
label_4_99 = clf.predict(x_test_pca[labels[3]])
print(labels[3], metrics.accuracy_score(y_valid_pca[labels[3]], y_pred_label_4_99)) #0.9626666666666667

"""Making Output Dataset"""

id_values = list(range(1, 745))
output_df = pd.DataFrame({
    'ID': id_values,
    'label_1': label_1_99,
    'label_2': label_2_99,
    'label_3': label_3_99,
    'label_4': label_4_99,
})

output_df

"""Writing to the CSV file"""

output_df.to_csv('./8/8.csv', index=False)